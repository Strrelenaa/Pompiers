import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import statsmodels.api as sm
from statsmodels.formula.api import ols
import matplotlib.pyplot as plt
import joblib

import time
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, root_mean_squared_error, classification_report, confusion_matrix, accuracy_score

st.markdown(
    """
    <style>
    /* Changer la couleur des titres */
    h1 {
        color: #C00000;
        font-weight: bold; /* Mettre les titres en gras */
    }

    /* Changer la couleur des titres */
    h2 {
        color: #0F4761;
        font-weight: bold; /* Mettre les titres en gras */
    }

    /* Changer la couleur des titres */
    h3 {
        color: #0F4761;
        font-weight: normal; /* Mettre les titres h2 sans gras */
    }
    """,
    unsafe_allow_html=True)

LFB = pd.read_csv("FINAL_LFB Mobilisation & Incident data from 2018 - 2023.zip", compression='zip')
@st.cache_data
def load_data():
    df_final = pd.read_csv("FINAL_LFB Mobilisation & Incident data from 2018 - 2023.zip", compression='zip', encoding='ISO-8859-1', sep=',', on_bad_lines='skip')
    return df_final

df_final = load_data()

st.title("Projet de pr√©diction du temps de r√©ponse de la Brigade des Pompiers de Londres")
st.sidebar.title("Sommaire")
pages=["Introduction ‚õëÔ∏è", "Exploration des donn√©es üîé", "DataVizualization üìä", "Mod√©lisation par R√©gression üõ†Ô∏è", 
       "Mod√©lisation par Classification üõ†Ô∏è","Conclusion üìå"]
page=st.sidebar.radio("Aller vers", pages)

st.sidebar.title("Cursus")

st.sidebar.markdown(f"""
<div style="display: flex; align-items: center;">
    <p style="margin: 0;">Data Analyst</p>
    </a>
</div>
""", unsafe_allow_html=True)

st.sidebar.markdown(f"""
<div style="display: flex; align-items: center;">
    <p style="margin: 0;">Bootcamp - Septembre 2024</p>
    </a>
</div>
""", unsafe_allow_html=True)

st.sidebar.title("Participants au projet")

# URL de l'image du logo LinkedIn
linkedin_logo_url = "https://content.linkedin.com/content/dam/me/business/en-us/amp/brand-site/v2/bg/LI-Bug.svg.original.svg"

# URL vers votre profil LinkedIn Julie Adeline
linkedin_profile_julieA_url = "https://www.linkedin.com/in/julie-adeline/"  # Remplacez par votre URL LinkedIn
# Utiliser Markdown pour afficher le logo et le nom sur la m√™me ligne
st.sidebar.markdown(f"""
<div style="display: flex; align-items: center;">
    <p style="margin: 0;">Julie ADELINE</p>
    <a href="{linkedin_profile_julieA_url}" target="_blank" style="margin-left: 8px;">
        <img src="{linkedin_logo_url}" alt="LinkedIn" style="width:20px; height:20px; position: relative; top: -2px;">
    </a>
</div>
""", unsafe_allow_html=True)

# URL vers votre profil LinkedIn Elena Stratan
linkedin_profile_Elena_url = "https://www.linkedin.com/in/elena-stratan/"  # Remplacez par votre URL LinkedIn
# Utiliser Markdown pour afficher le logo et le nom sur la m√™me ligne
st.sidebar.markdown(f"""
<div style="display: flex; align-items: center;">
    <p style="margin: 0;">Elena STRATAN</p>
    <a href="{linkedin_profile_Elena_url}" target="_blank" style="margin-left: 8px;">
        <img src="{linkedin_logo_url}" alt="LinkedIn" style="width:20px; height:20px; position: relative; top: -2px;">
    </a>
</div>
""", unsafe_allow_html=True)

# URL vers votre profil LinkedIn Julie Deng
linkedin_profile_JulieD_url = "https://www.linkedin.com/in/jjdeng/"  # Remplacez par votre URL LinkedIn
# Utiliser Markdown pour afficher le logo et le nom sur la m√™me ligne
st.sidebar.markdown(f"""
<div style="display: flex; align-items: center;">
    <p style="margin: 0;">Julie DENG</p>
    <a href="{linkedin_profile_JulieD_url}" target="_blank" style="margin-left: 8px;">
        <img src="{linkedin_logo_url}" alt="LinkedIn" style="width:20px; height:20px; position: relative; top: -2px;">
    </a>
</div>
""", unsafe_allow_html=True)

st.sidebar.title("Donn√©es")
st.sidebar.markdown("""
        [Ville de Londres](https://data.london.gov.uk/)
    """)

if page==pages[0]:
    st.image("lfb.png")
    st.header("Introduction ‚õëÔ∏è")
    
    st.write("Portant sur les interventions des Pompiers de Londres entre 2018 et 2023, notre projet\
        cherche √† r√©v√©ler les facteurs d√©terminant le temps de r√©ponse des pompiers\
        et √† r√©aliser des pr√©dictions √† partir de ces variables explicatives.")
    st.subheader("Variable cible: le temps de r√©ponse de la LFB")
    st.image('response_time.png')
   
if page==pages[1] :
    st.image("lfb.png")
    st.header("Exploration des donn√©esüîé")
    st.subheader("Aper√ßu g√©n√©ral des donn√©es")
    st.write("Cette section pr√©sente un aper√ßu des diff√©rentes donn√©es utilis√©es pour l'analyse.")
    
# S√©lection du jeu de donn√©es
    dataset_choice = st.radio("Choisissez un jeu de donn√©es √† explorer", 
                              ["Incidents (2018-2024)", "Mobilisation (2015-2020)", "Mobilisation (2021-2024)", "Jeu de donn√©es final : 2018 - 2023"])
    
    if dataset_choice == "Incidents (2018-2024)":
        st.subheader("1. Source")
        st.markdown("Le jeu de donn√©es provient du site du gouvernement de Londres : [London Fire Brigade Incident Records](https://data.london.gov.uk/dataset/london-fire-brigade-incident-records)")
        
        st.subheader("2. P√©riode")
        st.markdown("Les donn√©es sont mises √† jour r√©guli√®rement  et d√©butent en 2018.")
        
        st.subheader("3. Exploration des donn√©es")
        st.markdown("**Langage utilis√©** : Python")
        st.markdown(f"**Taille du DataFrame** : 759359 lignes x 39 colonnes")

        # Affichage des premi√®res lignes
        st.markdown("**Les premi√®res lignes de ce jeu de donn√©es :**")
        df_preview_incidents = pd.read_csv("df_incident_head.csv")
        st.write(df_preview_incidents.head())

        # Affichage du r√©sum√© statistique
        df_describe_incidents = pd.read_csv("describe_df_incident.csv")
        st.markdown("**R√©sum√© statistique de tout le jeu de donn√©es :**")
        st.write(df_describe_incidents)

        df_nan_incidents = pd.read_csv("NaN_df_incident.csv")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Valeurs manquantes :**")
            st.write(df_nan_incidents)
        with col2:
            st.markdown("**Informations :**")
            st.image("Inc2018.png")

    elif dataset_choice == "Mobilisation (2015-2020)":
        st.subheader("1. Source")
        st.markdown("Le jeu de donn√©es provient du site du gouvernement de Londres : [Mobilisation Data](https://data.london.gov.uk/dataset/london-fire-brigade-mobilisation-records)")

        st.subheader("2. P√©riode")
        st.markdown("Les donn√©es couvrent la p√©riode de 2015 √† 2020.")
        
        st.subheader("3. Exploration des donn√©es")
        st.markdown("**Langage utilis√©** : Python")
        st.markdown(f"**Taille du DataFrame** : 883641 lignes x 22 colonnes")
        df_head_mob_1520 = pd.read_csv("head_df_mob_1520.csv")
        st.write(df_head_mob_1520)
        st.markdown("**R√©sum√© statistique de tout le jeu de donn√©es :**")
        df_describe_mob_1520 = pd.read_csv("describe_df_mob_1520.csv")
        st.write(df_describe_mob_1520)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Valeurs manquantes :**")
            df_nan_mob_1520 = pd.read_csv("NaN_df_mob_1520.csv")
            st.write(df_nan_mob_1520)
        with col2:
            st.markdown("**Informations :**")
            st.image("Mob2015.png")
        
    elif dataset_choice == "Mobilisation (2021-2024)":
        st.subheader("1. Source")
        st.markdown("Le jeu de donn√©es provient du site du gouvernement de Londres : [Mobilisation Data](https://data.london.gov.uk/dataset/london-fire-brigade-mobilisation-records)")
        st.subheader("2. P√©riode")
        st.markdown("Les donn√©es couvrent la p√©riode de 2021 √† 2024.")
        
        st.subheader("3. Exploration des donn√©es")
        st.markdown("**Langage utilis√©** : Python")
        st.markdown(f"**Taille du DataFrame** : 659200 lignes x 24 colonnes")
        st.markdown("**Les premi√®res lignes de ce jeu de donn√©es :**")
        df_head_mob_2124 = pd.read_csv("head_df_mob_2124.csv")
        st.write(df_head_mob_2124)
        st.markdown("**R√©sum√© statistique de tout le jeu de donn√©es :**")
        df_describe_mob_2124 = pd.read_csv("describe_df_mob_2124.csv")
        st.write(df_describe_mob_2124)

        col1, col2 = st.columns(2)
        with col1: 
            st.markdown("**Valeurs manquantes :**")
            df_nan_mob_2124 = pd.read_csv("NaN_df_mob_2124.csv")
            st.write(df_nan_mob_2124)
        with col2:
            st.markdown("**Informations :**")
            st.image("Mob2021.png")
        
    elif dataset_choice == "Jeu de donn√©es final : 2018 - 2023":
        st.subheader("1. Source")
        st.markdown("Le jeu de donn√©es est une fusion des 3 jeux de donn√©es pr√©c√©dents regroupant les incidents et les mobilisations.")        
        st.subheader("2. P√©riode")
        st.markdown("Les donn√©es couvrent la p√©riode de 2018 √† 2023.")
        st.subheader("3. Feature Engineering")
        st.markdown("Afin de continuer notre √©tude sur le temps de r√©ponse de la Brigade des Pompiers de Londres, nous avons r√©alis√© des modifications sur nos jeux de donn√©es pour obtenir un fichier final exploitable et pertinent.")
        st.markdown("Pour cela, nous avons :")
        st.markdown("- Supprim√© les colonnes non n√©cessaire √† notre √©tude,")
        st.markdown("- Cr√©√© la variable cible 'ResponseTimeSeconds'")

        st.subheader("4. Fusion des donn√©es")
        st.markdown("**Langage utilis√©** : Python")
        st.markdown(f"**Taille du DataFrame** : 634025 lignes x 22 colonnes")
        st.markdown("**Les premi√®res lignes de ce jeu de donn√©es :**")
        df_head_final = pd.read_csv("head_df_final.csv")
        st.write(df_head_final)
        st.markdown("**R√©sum√© statistique de tout le jeu de donn√©es :**")
        df_describe_final = pd.read_csv("describe_df_final.csv")
        st.write(df_describe_final)

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Valeurs manquantes :**")
            df_nan_final = pd.read_csv("NaN_df_final.csv")
            st.write(df_nan_final)
        with col2:
            st.markdown("**Informations :**")
            st.image("final.png")

if page==pages[2] :
    st.image("lfb.png")
    st.header("DataVizualization üìä")
    
    categories=["Analyses Univari√©es", "Analyses Multivari√©es", "Analyses Statistiques"]
    categorie=st.selectbox("Types d'analyses", categories)

    if categories[0] in categorie :

        types=["Incidents par types", "Incidents par p√©riodes", "Incidents par localisation"]
        type=st.multiselect("S√©lection", types)

        if types[0] in type : 
            
            #Cr√©ation d'un groupe avec le d√©compte par type d'incident par ann√©es
            incident_counts = LFB.groupby(['CalYear'])['IncidentGroup'].value_counts().unstack()
        
            #Cr√©ation d'un graphique en barre empil√©e pour visualisier la r√©partition des incidents par type par ann√©es
            fig=plt.figure(figsize=(5,4))
            incident_counts.plot(kind='bar', stacked=True, ax=fig.gca())
            plt.xlabel("Ann√©es")
            plt.ylabel("Nombre d'incidents")
            plt.title("Nombre d'incidents par ann√©es par type d'incident")
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            plt.xticks(rotation=360)
            st.pyplot(fig)

            #Cr√©ation d'un graphique pour visualiser la r√©partition des types d'incidents
            fig=plt.figure(figsize=(7,4))
            sns.countplot(x='IncidentGroup',data=LFB)
            plt.xlabel("Types d'incidents")
            plt.ylabel("Nombre d'incidents")
            plt.xticks(["Special Service","Fire","False Alarm"],["Special Service","Feu","Fausse alarme"])
            plt.title("Types d'incidents")
            st.pyplot(fig)

            #Ajout des explications des deux graphiques
            st.write("Nous constatons que la r√©partition des types d‚Äôincident par ann√©e est sensiblement la m√™me avec environ 50% de d√©placements pour fausses alertes, 30% de d√©placements pour causes de services sp√©ciaux et 20% de d√©placements pour des incendies.")
            st.write("De plus, il ne semble pas y avoir de diff√©rences entre le nombre d'incidents par ann√©es.")
            st.write("Il semble y avoir eu un l√©ger recul du nombre d'incidents en 2020 pendant le COVID suivie d'une l√©g√®re hausse des incidents en 2021,2022 et 2023.")

            # Retirer de la colonne SpecialService les entr√©es qui ne sont pas des SpecialService
            Special_Service=LFB.loc[LFB['SpecialServiceType']!='Not a special service']

            #Faire le d√©compte de toutes les valeurs de SpecialService
            counts = Special_Service['SpecialServiceType'].value_counts().reset_index()

            #Trier cette liste dans l'ordre d√©croissant
            counts.columns = ['Special_Service', 'nombre']
            counts = counts.sort_values(by='nombre', ascending=False)

            #Cr√©ation d'un graphique pour visualiser les types de special service tri√©s par ordre d'importance
            fig=plt.figure(figsize=(7,5))
            sns.barplot(y='Special_Service', x='nombre', data=counts, order=counts['Special_Service'])
            plt.xlabel('Types de Special Service')
            plt.ylabel('Nombre')
            plt.title("Nombre d'incidents par type de Special Service")
            st.pyplot(fig)

            #Ajouter des explications
            st.write("Nous avons pu constater qu'environ 30% des activit√©s des pompiers de la Brigade de Londres concernent des services sp√©ciaux autre que la gestion des incendies.")
            st.write("On peut constater que la majorit√© de ces services sp√©ciaux concernent des ouvertures de portes (hors incendies et urgences vitales) des inondations, des accidents de la route (RTC) et de l'assistance aux personnes bloqu√©s dans des ascenseurs. ")

            #Cr√©ation d'une variable pour visualiser le TOP5 des lieux avec le plus d'incidents
            Top_PropertyCategory=LFB['PropertyCategory'].value_counts().head()

            #Cr√©ation d'un graphique pour visualiser le TOP5 des lieux avec le plus d'incidents
            fig=plt.figure(figsize=(8,5))
            sns.barplot(x=Top_PropertyCategory.values,y=Top_PropertyCategory.index)
            plt.ylabel("Types de lieux")
            plt.xlabel("Nombre d'incidents")
            plt.title("Top 5 des cat√©gories de lieux avec le plus d'incidents")
            st.pyplot(fig)

            #Ajout des explications
            st.write("On constate dans cette variable une disparit√© importante avec une tr√®s forte majorit√© des incidents ayant lieu dans les habitations r√©sidentielles.")

        if types[1] in type : 
            #Cr√©ation d'un graphique en barre pour visualisier la distribution des incidents par mois
            fig=plt.figure(figsize=(10,6))
            sns.countplot(x='CalMonth',data=LFB,hue='CalMonth',legend=False,palette='rainbow')
            plt.xlabel("Mois")
            plt.ylabel("Nombre d'incidents")
            plt.title("Nombre d'incidents par mois")
            plt.xticks([0,1,2,3,4,5,6,7,8,9,10,11],["Janvier","F√©vrier","Mars","Avril","Mai","Juin","Juillet","Aout","Septembre","Octobre","Novembre","D√©cembre"],
                    rotation=45, ha='right')
            st.pyplot(fig)

            #Cr√©ation d'un graphique en barre pour visualisier la distribution des incidents par jours de la semaine
            fig=plt.figure(figsize=(8,4))
            sns.countplot(x='CalWeekday',data=LFB,hue='CalWeekday',legend=False,palette='rainbow')
            plt.xlabel("Mois")
            plt.ylabel("Nombre d'incidents")
            plt.title("Nombre d'incidents par jours de la semaine")
            plt.xticks([0,1,2,3,4,5,6],["Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Dimanche"],rotation=45,ha='right')
            st.pyplot(fig)

            #Cr√©ation d'un graphique en barre pour visualisier la distribution des incidents par heures de la journ√©e
            fig=plt.figure(figsize=(8,5))
            sns.countplot(x='HourOfCall',data=LFB,hue='HourOfCall',legend=False,palette='rainbow')
            plt.xlabel("Mois")
            plt.ylabel("Nombre d'incidents")
            plt.title("Nombre d'incidents par heures de la journ√©e")
            plt.xticks([0,6,12,18,23],['Minuit','6h','Midi','18h','23h'])
            st.pyplot(fig)

            #Ajout des explications des graphiques temporels
            st.write("Le nombre d'incident semble √©galement r√©partis sur l'ensemble des mois de l'ann√©e √† part un l√©ger pic en √©t√©.")
            st.write("Le nombre d'incident semble √©galement r√©partis sur l'ensemble de la semaine.")
            st.write("On constate que une disparit√© de la r√©partition du nombre d'incidents selon l'heure de la journ√©e.")
            st.write("Il semble y avoir plus d'incidents en journ√©e que la nuit, avec un pic aux heures de pointes entre 17h et 20h.")
        
        if types[2] in type :
           #Cr√©ation d'une variable pour visualiser le TOP10 des quartiers avec le plus d'incidents
            Top_Borough=LFB['IncGeo_BoroughName'].value_counts().head(10)

            #Cr√©ation d'un graphique pour visualiser le TOP10 des lieux avec le plus d'incidents
            fig=plt.figure(figsize=(8,5))
            sns.barplot(x=Top_Borough.values,y=Top_Borough.index)
            plt.ylabel("Noms de quartier")
            plt.xlabel("Nombre d'incidents")
            plt.title("Top 10 des quartiers de Londres avec le plus d'incidents")
            st.pyplot(fig)

            #Cr√©ation d'une variable avec les lignes du quartier de Westminster
            West=LFB[(LFB['IncGeo_BoroughName']=='WESTMINSTER')]

            #Cr√©ation d'une variable pour visualiser le TOP5 des ward avec le plus d'incidents dans le quartier de Westminster
            West_no_other=West[West['IncGeo_WardName']!='OTHERS']
            Top_Ward=West_no_other['IncGeo_WardName'].value_counts().head(5)

            #Cr√©ation d'un graphique pour visualiser le TOP5 des ward de westminster avec le plus d'incidents
            fig=plt.figure(figsize=(7,5))
            sns.barplot(x=Top_Ward.values,y=Top_Ward.index)
            plt.ylabel("Noms des ward")
            plt.xlabel("Nombre d'incidents")
            plt.title("Top 5 des wards de Westminster avec le plus d'incidents")
            st.pyplot(fig)

            #Ajout des explications 
            st.write("Une derni√®re observation int√©ressante est que les incidents sont r√©partis de mani√®re √©quitable entre les diff√©rents quartiers, √† l'exception du quartier de Westminster qui recense pr√®s du double d‚Äôincidents en plus que les autres quartiers.")
            st.write("Nous sommes all√©es plus loin et dans le quartier de Westminster, il y a deux wards (ou circonscriptions) qui ont une plus forte densit√© d'incidents : West End et St James's.")
            st.write("Cela peut s'expliquer par le fait que St James's et West End sont deux zones de Londres qui concentrent beaucoup de commerces et de lieux touristiques, politiques et culturels. En effet, on peut y trouver le Parlement britannique, Soho, Mayfair, la National Gallery et l'abbaye de Westminster.")

    if categories[1] in categorie :
        
        types=["Distribution du temps de r√©ponse", "Temps de r√©ponse par p√©riodes", "Temps de r√©ponse par lieux de d√©ploiements"]
        type=st.multiselect("S√©lection", types)

        if types[0] in type :   
            
            #Visualisation de la distribution du temps de r√©ponse en secondes
            fig=plt.figure(figsize=(10,5))
            sns.boxplot(x=LFB['ResponseTimeSeconds'])
            plt.xticks([0,100,200,300,400,500,600,700,800,900,1000,1100,1200])
            plt.xlabel("Temps de r√©ponse en secondes")
            plt.title("Boxplot des temps de r√©ponse")
            st.pyplot(fig)

            #Information sur la donn√©e
            st.dataframe(LFB['ResponseTimeSeconds'].describe())

            #Ajout des explications
            st.write("Les valeurs au-del√† de 500 semblent plut√¥t des valeurs extr√™mes lors d'op√©rations plus longues. La distribution du temps de r√©ponse pose une moyenne √† 313 secondes et une m√©diane √† 300 secondes. Soit environ 5 minutes entre le moment o√π les pompiers sont mobilis√©s et le moment o√π ils arrivent sur les lieux de l'incident.")

        if types[1] in type : 

            #Cr√©ation d'un graphique permettant de visualiser l'√©volution du temps de r√©ponse par mois et par ann√©es
            fig=plt.figure(figsize=(10,6))
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2018],errorbar=None,color='blue',alpha=0.8,label=2018)
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2019],errorbar=None,color='green',alpha=0.8,label=2019)
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2020],errorbar=None,color='red',alpha=0.8,label=2020)
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2021],errorbar=None,color='violet',alpha=0.8,label=2021)
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2022],errorbar=None,color='yellow',alpha=0.8,label=2022)
            sns.lineplot(x='CalMonth',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2023],errorbar=None,color='orange',alpha=0.8,label=2023)
            plt.legend()
            plt.ylim(260,360)
            plt.xlim(1,12)
            plt.xlabel("Mois")
            plt.xticks([1,2,3,4,5,6,7,8,9,10,11,12],
                       ["Janvier","F√©vrier","Mars","Avril","Mai","Juin","Juillet","Aout","Septembre","Octobre","Novembre","D√©cemnbre"],rotation=45,ha='right')
            plt.title("Evolution du temps de r√©ponse moyen par mois et par ann√©es")
            st.pyplot(fig)

            #Ajout des explications
            st.write("On constate que le temps de r√©ponse est g√©n√©ralement situ√© entre 300 et 320 secondes (soit entre 5 minutes et 5 minutes trente).")
            st.write("Ce temps de r√©ponse augmente lors des mois d'√©t√©, et en particulier les mois de Juillet avec des pics jusqu'√† 340 secondes.")
            st.write("L'ann√©e 2020 est visiblement une anomalie avec, entre Avril et Aout ,des temps de r√©ponses bien inf√©rieurs √† la moyenne des autres ann√©es.")
            st.write("Cela peut s'expliquer par l'impact des restrictions sanitaires du COVID. Les gens √©tant confin√©s chez eux, le nombre d'incidents a baiss√© sur cette p√©riode.")

            #Cr√©ation d'un graphique permettant de visualiser l'√©volution du temps de r√©ponse par jours de la semaine et par ann√©es
            fig=plt.figure(figsize=(10,6))
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2018],errorbar=None,color='blue',alpha=0.8,label=2018)
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2019],errorbar=None,color='green',alpha=0.8,label=2019)
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2020],errorbar=None,color='red',alpha=0.8,label=2020)
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2021],errorbar=None,color='violet',alpha=0.8,label=2021)
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2022],errorbar=None,color='yellow',alpha=0.8,label=2022)
            sns.lineplot(x='CalWeekday',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2023],errorbar=None,color='orange',alpha=0.8,label=2023)
            plt.legend()
            plt.ylim(290,340)
            plt.xlim(0,6)
            plt.ylabel("Temps de r√©ponse en secondes")
            plt.xlabel("Jours de la semaine")
            plt.xticks([0,1,2,3,4,5,6],["Lundi","Mardi","Mercredi","Jeudi","Vendredi","Samedi","Dimanche"],rotation=360)
            plt.title("Evolution du temps de r√©ponse moyen par jours de la semaine")
            st.pyplot(fig)

            #Ajout des explications
            st.write("Comme sur le graphique pr√©c√©dent, on constate que le temps de r√©ponse de 2020 est bien inf√©rieur √† ceux des autres ann√©es.")
            st.write("Cependant, on distingue une tendance avec un temps de r√©ponse en hausse le vendredi et en baisse le weekend.")
            st.write("Le dimanche semble √™tre le jour de la semaine avec le temps de r√©ponse le plus rapide. Probablement car c'est un jour de repos o√π les gens restent chez eux.")

            #Cr√©ation d'un graphique permettant de visualiser l'√©volution du temps de r√©ponse par heures de la journ√©e et par ann√©es
            fig=plt.figure(figsize=(10,6))
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2018],errorbar=None,color='blue',alpha=0.8,label=2018)
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2019],errorbar=None,color='green',alpha=0.8,label=2019)
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2020],errorbar=None,color='red',alpha=0.8,label=2020)
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2021],errorbar=None,color='violet',alpha=0.8,label=2021)
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2022],errorbar=None,color='yellow',alpha=0.8,label=2022)
            sns.lineplot(x='HourOfCall',y='ResponseTimeSeconds',data=LFB[LFB['CalYear']==2023],errorbar=None,color='orange',alpha=0.8,label=2023)
            plt.legend()
            plt.ylim(260,360)
            plt.xlim(0,23)
            plt.xlabel("Heures")
            plt.xticks([0,3,6,9,12,15,18,21,23],['Minuit','3h','6h','9h','Midi','15h','18h','21h','23h'])
            plt.title("Evolution du temps de r√©ponse moyen par heures")
            st.pyplot(fig)

            #Ajout des explications
            st.write("Le temps de r√©ponse varie selon le moment de la journ√©e.")
            st.write("En effet, on constate qu'il est en moyenne entre 300 et 340 secondes entre 1h et 6h du matin puis de 11h √† 18h. Il baisse drastiquement autour de 9h et de 22h.")
            st.write("Sur l'ann√©e 2020, le temps de r√©ponse semble similaire √† celui des autres ann√©es √† la diff√©rence de la journ√©e entre 10h et 21h o√π il est bien inf√©rieur.")

        if types[2] in type :

            #Cr√©ation d'un graphique pour visualiser la relation entre la caserne de d√©ploiement et le temps de r√©ponse
            fig=plt.figure(figsize=(4,4))
            sns.boxplot(x='DeployedFromLocation',y='ResponseTimeSeconds',data=LFB)
            plt.ylim(0,1300)
            plt.ylabel("Temps de r√©ponse en secondes")
            plt.title("Relation entre la caserne de d√©ploiement et le temps de r√©ponse")
            st.pyplot(fig)

            #Ajout des explications
            st.write("La m√©diane du temps de r√©ponse ne semble pas fluctuer selon le lieu de d√©ploiement des pompiers. Cependant, les valeurs sont plus dispers√©es lorsque les pompiers sont d√©ploy√©s depuis une caserne qui n'est pas la leur.")

            #Cr√©ation d'un graphique pour visualiser la relation entre le quartier de l'incident et le temps de r√©ponse
            fig=plt.figure(figsize=(20,4))
            sns.boxplot(x='IncGeo_BoroughName',y='ResponseTimeSeconds',data=LFB)
            plt.ylim(0,1300)
            plt.xticks(rotation=45,ha='right')
            plt.ylabel("Temps de r√©ponse en secondes")
            plt.xlabel("Quarties de Londres")
            plt.title("Relation entre les types d'incident et le temps de r√©ponse")
            st.pyplot(fig)

            #Ajout des explications
            st.write("On constate que la m√©diane du temps de r√©ponse semble √™tre assez similaire dans la plupart des quartiers √† l'exception de Bromley,Enfield,Tower Hamlets, Kensington and Chealsea.")
            st.write("Cependant, on constate qu'il existe des disparit√©s au niveau des quartiles plus ou moins importants.")
    
    if categories[2] in categorie :
              
        # Liste des variables cat√©gorielles
        var_cat = ['CalMonth', 'CalWeekday', 'HourOfCall', 'DeployedFromLocation', 'IncGeo_BoroughName']

        # Supression des NaNs
        LFB_anova = LFB.dropna(subset=['ResponseTimeSeconds'] + var_cat)

        # Formule du mod√®le
        formule  = 'ResponseTimeSeconds ~ C(CalMonth) + C(CalWeekday) + C(HourOfCall) + C(DeployedFromLocation) + C(IncGeo_BoroughName)'
        model = ols(formule, data=LFB_anova).fit()

        # ANOVA
        anova_table = sm.stats.anova_lm(model, typ=2)
        
        # Sauvegarde du tableau ANOVA dans un fichier
        joblib.dump(anova_table, 'anova_file')

        # Formatage des valeurs de la table en notation scientifique
        anova_table['sum_sq'] = anova_table['sum_sq'].apply(lambda x: f"{x:.3e}")
        anova_table['PR(>F)'] = anova_table['PR(>F)'].apply(lambda x: f"{x:.3e}")

        #Affichage du tableau ANOVA
        st.table(anova_table)

        #Ajout des explications
        st.write("On remarque que pour l'ensemble des variables cat√©gorielles, la p-value est inf√©rieure √† 5%.")
        st.write("Nous pouvons en d√©duire que chaque variable a un effet significatif sur le temps de r√©ponse.")

if page==pages[3] :
    st.image("lfb.png")    
    st.header("Mod√©lisation par R√©gression üõ†Ô∏è")

    st.subheader("Objectif")
    st.write("Pr√©dire le temps de r√©ponse de la Brigade des Pompiers de Londres")
 
    st.subheader("1. √âtapes de Preprocessing & Mod√©lisation")
    st.markdown(""" 
                1. S√©paration en jeux de d'entrainement (75%) et de test (25%)
                2. Gestion des valeurs nulles
                3. Standardisation des donn√©es num√©riques
                4. Encodage des valeurs cat√©gorielles avec OneHotEncoder
                5. Transformation des variables circulaires (CalMonth, CalHour, CalWeekday)
                6. Instanciation & entrainement des mod√®les
                7. Pr√©dictions de chaque mod√®le sur le jeu de test 
                8. Calcul des m√©triques de performance
                """)
    

    # Fonction de pr√©paration des donn√©es avec mise en cache
    @st.cache_data
    def prepare_data(LFB):
        #S√©paration des variable explicatives et de la variable cible
        X=LFB.drop('ResponseTimeSeconds',axis=1)
        y=LFB['ResponseTimeSeconds']
            
        #Cr√©ation des ensembles d'entrainement et de test
        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

        #Remplacement des valeurs manquantes de DeployedFromLocation & DelayCodeId par le mode
        imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
        X_train[['DeployedFromLocation','DelayCode_Description']] = imputer.fit_transform(X_train[['DeployedFromLocation','DelayCode_Description']])
        X_test[['DeployedFromLocation','DelayCode_Description']] = imputer.transform(X_test[['DeployedFromLocation','DelayCode_Description']])

        #Remplacement des valeurs manquantes de SpecialServiceType par la valeur 'Not a Special Service'
        imputer = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value='Not a Special Service')
        X_train['SpecialServiceType'] = imputer.fit_transform(X_train[['SpecialServiceType']]).ravel()
        X_test['SpecialServiceType'] = imputer.transform(X_test[['SpecialServiceType']]).ravel()    

        #Suppression des lignes restantes avec des valeurs manquantes non rempla√ßables
        X_train=X_train.dropna()
        X_test=X_test.dropna() 

        #Suppression des lignes correspondantes dans y_train & y_test
        y_train = y_train.loc[X_train.index]
        y_test = y_test.loc[X_test.index] 

        #V√©rification que les index sont align√©s avant la transformation
        X_train = X_train.reset_index(drop=True)
        X_test = X_test.reset_index(drop=True) 

        #Stocker les variables num√©riques dans des dataframes nomm√©s num_train & num_test
        num_train=X_train[['Easting_rounded','Northing_rounded',"PumpCount"]].astype(np.int8)

        num_test=X_test[['Easting_rounded','Northing_rounded','PumpCount']].astype(np.int8)

        #Stocker les variables cat√©gorielles dans des dataframes nomm√©s cat_train & cat_test
        cat_train=X_train[['IncidentGroup','StopCodeDescription','SpecialServiceType','PropertyCategory','PropertyType','AddressQualifier',
                               'Postcode_district','IncGeo_BoroughName','IncGeo_WardName','IncidentStationGround', 'NumStationsWithPumpsAttending',
                               'DeployedFromStation_Code','DeployedFromLocation','DelayCode_Description','CalYear']].astype(str)

        cat_test=X_test[['IncidentGroup','StopCodeDescription','SpecialServiceType','PropertyCategory','PropertyType','AddressQualifier', 
                             'Postcode_district','IncGeo_BoroughName','IncGeo_WardName','IncidentStationGround','NumStationsWithPumpsAttending',
                             'DeployedFromStation_Code','DeployedFromLocation','DelayCode_Description','CalYear']].astype(str)

        # Stocker les variables circulaires
        circ_train=X_train[['HourOfCall','CalWeekday','CalMonth']]
        circ_test=X_test[['HourOfCall','CalWeekday','CalMonth']]

        # Standardiser les variables num√©riques
        scaler = StandardScaler()

        # Ajuster le scaler sur les donn√©es d'entra√Ænement et transformer les donn√©es d'entra√Ænement et de test
        num_train_sc = scaler.fit_transform(num_train)
        num_test_sc = scaler.transform(num_test)

        # Cr√©ation des DataFrames avec les noms de colonnes appropri√©s
        num_train_sc_df = pd.DataFrame(num_train_sc, columns=num_train.columns, index=num_train.index)
        num_test_sc_df = pd.DataFrame(num_test_sc, columns=num_test.columns, index=num_test.index) 

        # Encoder les variables cat√©gorielles
        ohe = OneHotEncoder(drop="first", sparse_output=False, handle_unknown="ignore")

        # Ajuster l'encodeur sur les donn√©es d'entra√Ænement et transformer les donn√©es d'entra√Ænement et de test
        cat_train_enc = ohe.fit_transform(cat_train)
        cat_test_enc = ohe.transform(cat_test)

        # R√©cup√©ration des noms des variables encod√©es
        cat_feature_names = ohe.get_feature_names_out(input_features=cat_train.columns)

        # Cr√©ation des DataFrames avec les noms de colonnes appropri√©s
        cat_train_enc_df = pd.DataFrame(cat_train_enc, columns=cat_feature_names, index=cat_train.index)
        cat_test_enc_df = pd.DataFrame(cat_test_enc, columns=cat_feature_names, index=cat_test.index)

        # Transformation des variables circulaires
        ## Mois (CalMonth: 1 √† 12)
        circ_train.loc[:,'CalMonth_sin']=np.sin(2 * np.pi * circ_train['CalMonth'] / 12)
        circ_train.loc[:,'CalMonth_cos']=np.cos(2 * np.pi * circ_train['CalMonth'] / 12)

        circ_test.loc[:,'CalMonth_sin']=np.sin(2 * np.pi * circ_test['CalMonth'] / 12)
        circ_test.loc[:,'CalMonth_cos']=np.cos(2 * np.pi * circ_test['CalMonth'] / 12)

        ## Jours de la semaine (CalWeekday: 1 √† 7)
        circ_train.loc[:,'CalWeekday_sin']=np.sin(2 * np.pi * circ_train['CalWeekday'] / 7)
        circ_train.loc[:,'CalWeekday_cos']=np.cos(2 * np.pi * circ_train['CalWeekday'] / 7)

        circ_test.loc[:,'CalWeekday_sin']=np.sin(2 * np.pi * circ_test['CalWeekday'] / 7)
        circ_test.loc[:,'CalWeekday_cos']=np.cos(2 * np.pi * circ_test['CalWeekday'] / 7)

        ## Heures de la journ√©e (HourOfCall: 0 √† 23)
        circ_train.loc[:,'HourOfCall_sin']=np.sin(2 * np.pi * circ_train['HourOfCall'] / 24)
        circ_train.loc[:,'HourOfCall_cos']=np.cos(2 * np.pi * circ_train['HourOfCall'] / 24)

        circ_test.loc[:,'HourOfCall_sin']=np.sin(2 * np.pi * circ_test['HourOfCall'] / 24)
        circ_test.loc[:,'HourOfCall_cos']=np.cos(2 * np.pi * circ_test['HourOfCall'] / 24)

        # Concat√©ner les DataFrames pour former X_train et X_test
        X_train = pd.concat([cat_train_enc_df, num_train_sc_df, circ_train], axis=1)
        # Reconstitution des jeux de donn√©es
        X_test = pd.concat([cat_test_enc_df, num_test_sc_df, circ_test], axis=1)

        return X_train, X_test, y_train, y_test

    # Chargement des donn√©es pr√©par√©es avec cache
    X_train, X_test, y_train, y_test = prepare_data(LFB)

    st.subheader("2 .Choix du mod√®le")

    regressions=["lineaire", "Ridge", "SVR", "Arbre", "RandomForest", "GradientBoosting"]
    regression=st.radio("‚ö†Ô∏è Attention : cela peut prendre quelques minutes", regressions, key="modele_regression")

    if regression=="lineaire":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        model_filename = 'model_lin_reg.joblib'

        try:
            # Tenter de charger le mod√®le existant
            lin_reg = joblib.load(model_filename)
        except FileNotFoundError:
            # Si le mod√®le n'existe pas, on l'entra√Æne
            st.write("Entra√Ænement du mod√®le de r√©gression lin√©aire...")
            lin_reg = LinearRegression()
            lin_reg.fit(X_train, y_train)
                
            # Sauvegarder le mod√®le entra√Æn√©
            joblib.dump(lin_reg, model_filename)
            st.write("Mod√®le de r√©gression lin√©aire entra√Æn√© et sauvegard√©.")
            
        # Pr√©dictions sur les donn√©es de test
        y_pred_lin = lin_reg.predict(X_test)

        # √âvaluation du mod√®le
        # Calcul des scores R¬≤ sur l'entra√Ænement et le test
        train_score_lin = lin_reg.score(X_train, y_train)
        test_score_lin = lin_reg.score(X_test, y_test)

        # Calcul de l'√©cart de performance
        ecart_performance_lin = train_score_lin - test_score_lin

        mae = mean_absolute_error(y_test, y_pred_lin)
        mse = mean_squared_error(y_test, y_pred_lin)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, y_pred_lin)

        #Cr√©er un dictionnaire avec les r√©sultats
        performances = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                            "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_lin:.4f}", f"{test_score_lin:.4f}", f"{ecart_performance_lin:.4f}", 
                        f"{mae:.4f}", f"{mse:.4f}", f"{rmse:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        lin_performance = pd.DataFrame(performances)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de R√©gression Lin√©aire :")
        st.table(lin_performance)

    if regression=="Ridge":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        # Entra√Ænement du mod√®le si le fichier n'existe pas
        alpha_value = st.select_slider('Alpha', options=[0.01, 0.1, 1, 10, 100, 1000], key="alpha_slider")
        ridge_reg = Ridge(alpha=alpha_value, random_state=42)
        ridge_reg.fit(X_train, y_train)

        # Pr√©dictions sur les donn√©es de test
        y_train_pred_ridge = ridge_reg.predict(X_train)
        y_pred_ridge = ridge_reg.predict(X_test)

        # √âvaluation du mod√®le
        train_score_ridge = ridge_reg.score(X_train, y_train)
        test_score_ridge = ridge_reg.score(X_test, y_test)
        ecart_performance_ridge = train_score_ridge - test_score_ridge

        mae_ridge = mean_absolute_error(y_test, y_pred_ridge)
        mse_ridge = mean_squared_error(y_test, y_pred_ridge)
        rmse_ridge = np.sqrt(mse_ridge)

        # Cr√©er un dictionnaire avec les r√©sultats
        performances_ridge = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                            "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_ridge:.4f}", f"{test_score_ridge:.4f}", f"{ecart_performance_ridge:.4f}", 
                        f"{mae_ridge:.4f}", f"{mse_ridge:.4f}", f"{rmse_ridge:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        ridge_performance = pd.DataFrame(performances_ridge)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de R√©gression Ridge :")
        st.table(ridge_performance)

    if regression=="SVR":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        # Entra√Ænement du mod√®le
        kernel_options = {"Lin√©aire": "linear", "Non-Lin√©aire (RBF)": "rbf"}
        selected_kernel = st.selectbox("Type de kernel", list(kernel_options.keys()))
        kernel_type = kernel_options[selected_kernel]  # Map selected option to kernel value
        epsilon_value=st.slider("Epsilon", 0.01, 0.05, 0.01)
        C_value=st.slider("C", 1, 10, 1)
        Max_iter_value=st.slider("Max_iter", 1, 50, 10)
        svr_ln = SVR(kernel=kernel_type, epsilon=epsilon_value, C=C_value, max_iter=Max_iter_value)
        svr_ln.fit(X_train, y_train)

        # Pr√©dire la cible √† partir du test set des variables explicatives
        y_pred_SVR = svr_ln.predict(X_test)

        # √âvaluation du mod√®le
        # Calcul des scores R¬≤ sur l'entra√Ænement et le test
        train_score_SVR = svr_ln.score(X_train, y_train)
        test_score_SVR = svr_ln.score(X_test, y_test)

        # Calcul de l'√©cart de performance
        ecart_performance_SVR = train_score_SVR - test_score_SVR

        mae_SVR = mean_absolute_error(y_test, y_pred_SVR)
        mse_SVR = mean_squared_error(y_test, y_pred_SVR)
        rmse_SVR = np.sqrt(mse_SVR)
        
        #Cr√©er un dictionnaire avec les r√©sultats
        performances = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                        "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_SVR:.4f}", f"{test_score_SVR:.4f}", f"{ecart_performance_SVR:.4f}", 
                    f"{mae_SVR:.4f}", f"{mse_SVR:.4f}", f"{rmse_SVR:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        SVR_performance = pd.DataFrame(performances)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de R√©gression par vecteurs de support :")
        st.table(SVR_performance)

    if regression=="Arbre":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        st.write("Entra√Ænement du mod√®le arbre de d√©cision...")
        min_sample_leaf_values=st.slider("Min Sample Leaf", 1000, 10000, step=1000)
        dtr = DecisionTreeRegressor(criterion='squared_error', splitter='best', min_samples_leaf=min_sample_leaf_values)
        dtr.fit(X_train, y_train)
        st.write("Mod√®le arbre de d√©cision entra√Æn√© et sauvegard√©.")

        # Pr√©dire la cible √† partir du test set des variables explicatives
        y_pred_dtr = dtr.predict(X_test)

        # √âvaluation du mod√®le
        # Calcul des scores R¬≤ sur l'entra√Ænement et le test
        train_score_dtr = dtr.score(X_train, y_train)
        test_score_dtr = dtr.score(X_test, y_test)

        # Calcul de l'√©cart de performance
        ecart_performance_dtr = train_score_dtr - test_score_dtr

        mae_dtr = mean_absolute_error(y_test, y_pred_dtr)
        mse_dtr = mean_squared_error(y_test, y_pred_dtr)
        rmse_dtr = np.sqrt(mse_dtr)
        
        #Cr√©er un dictionnaire avec les r√©sultats
        performances = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                        "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_dtr:.4f}", f"{test_score_dtr:.4f}", f"{ecart_performance_dtr:.4f}", 
                    f"{mae_dtr:.4f}", f"{mse_dtr:.4f}", f"{rmse_dtr:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        dtr_performance = pd.DataFrame(performances)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de R√©gression par arbre de d√©cision :")
        st.table(dtr_performance)

    if regression=="RandomForest":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        # Entra√Ænement du mod√®le si le fichier n'existe pas
        st.write("Entra√Ænement du mod√®le Random Forest Regressor...")
        n_estimators_value=st.slider("N estimators", 5, 25, step=5)
        max_depth_value=st.slider("Max depth", 5, 15, step=1)
        rf = RandomForestRegressor(n_estimators=n_estimators_value,max_depth=max_depth_value, random_state=42)
        rf.fit(X_train, y_train)
        st.write("Mod√®le Random Forest Regressor entra√Æn√©.")

        # Pr√©dire la cible √† partir du test set des variables explicatives
        y_pred_rf = rf.predict(X_test)

        # √âvaluation du mod√®le
        # Calcul des scores R¬≤ sur l'entra√Ænement et le test
        train_score_rf = rf.score(X_train, y_train)
        test_score_rf = rf.score(X_test, y_test)

        # Calcul de l'√©cart de performance
        ecart_performance_rf = train_score_rf - test_score_rf

        mae_rf = mean_absolute_error(y_test, y_pred_rf)
        mse_rf = mean_squared_error(y_test, y_pred_rf)
        rmse_rf = np.sqrt(mse_rf)
        
        #Cr√©er un dictionnaire avec les r√©sultats
        performances = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                        "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_rf:.4f}", f"{test_score_rf:.4f}", f"{ecart_performance_rf:.4f}", 
                    f"{mae_rf:.4f}", f"{mse_rf:.4f}", f"{rmse_rf:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        rf_performance = pd.DataFrame(performances)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de Random Forest Regressor :")
        st.table(rf_performance)

    if regression=="GradientBoosting":

        if "last_selected_model" not in st.session_state:
            st.session_state["last_selected_model"] = None
        if regression != st.session_state["last_selected_model"]:
            st.cache_resource.clear()  # Nettoie le cache lorsque le mod√®le change
            st.session_state["last_selected_model"] = regression

        X_train.columns = X_train.columns.astype(str)
        X_test.columns = X_test.columns.astype(str)

        # Entra√Ænement du mod√®le si le fichier n'existe pas
        st.write("Entra√Ænement du mod√®le r√©gression par Gradient Boosting...")
        n_estimators_value=st.slider("N estimators", 5, 25, step=5)
        max_depth_value=st.slider("Max depth", 5, 15, step=1)
        reg = GradientBoostingRegressor(n_estimators=n_estimators_value,max_depth=max_depth_value, random_state=42)
        reg.fit(X_train, y_train)
        st.write("Mod√®le de r√©gression par Gradient Boosting entra√Æn√© et sauvegard√©.")

        # Pr√©dire la cible √† partir du test set des variables explicatives
        y_pred_reg = reg.predict(X_test)

        # √âvaluation du mod√®le
        # Calcul des scores R¬≤ sur l'entra√Ænement et le test
        train_score_reg = reg.score(X_train, y_train)
        test_score_reg= reg.score(X_test, y_test)

        # Calcul de l'√©cart de performance
        ecart_performance_reg = train_score_reg - test_score_reg

        mae_reg = mean_absolute_error(y_test, y_pred_rf)
        mse_reg = mean_squared_error(y_test, y_pred_rf)
        rmse_reg = np.sqrt(mse_reg)
        
        #Cr√©er un dictionnaire avec les r√©sultats
        performances = {
            "M√©trique": ["Train Score (R¬≤)", "Test Score (R¬≤)", "√âcart de Performance", 
                        "Mean Absolute Error (MAE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)"],
            "Valeur": [f"{train_score_reg:.4f}", f"{test_score_reg:.4f}", f"{ecart_performance_reg:.4f}", 
                    f"{mae_reg:.4f}", f"{mse_reg:.4f}", f"{rmse_reg:.4f}"]
        }

        # Cr√©er un DataFrame pour structurer les donn√©es
        reg_performance = pd.DataFrame(performances)

        # Afficher le tableau dans Streamlit
        st.write("Performances du mod√®le de r√©gression par Gradient Boosting :")
        st.table(reg_performance)
    

if page==pages[4] :
    st.image("lfb.png")
    st.header("Mod√©lisation par Classification üõ†Ô∏è")
    
    st.subheader("Objectif")
    st.write("Pr√©dire l'intervalle de temps de r√©ponse de la Brigade des Pompiers de Londres")

    st.subheader("1. Classification de la variable cible")
    st.write(":pushpin: _Distribution des valeurs avant la classification_")
    st.image('distri_cible.png')

    st.write(":pushpin: _R√©partition des classes apr√®s la classification_")
    df1 = pd.DataFrame([
        {"Dataset": "y_train", 
        "Tr√®s Lente\n(plus de 500 sec)": 32865, 
        "Lente\n(400-500 sec)": 69645, 
        "Mod√©r√©e\n(300-400 sec)": 75821, 
        "Rapide\n(200-300 sec)": 207009, 
        "Tr√®s Rapide\n(0-200 sec)": 90178},
        {"Dataset": "y_test", 
        "Tr√®s Lente\n(plus de 500 sec)": 11011, 
        "Lente\n(400-500 sec)": 23374, 
        "Mod√©r√©e\n(300-400 sec)": 25249, 
        "Rapide\n(200-300 sec)": 69026, 
        "Tr√®s Rapide\n(0-200 sec)": 29847}
        ])
    st.dataframe(df1, use_container_width=True, hide_index=True)

    st.subheader("2. Calcul du poids des classes ")
    df2 = pd.DataFrame(
        {"Tr√®s Lente": [2.8939049995435595],
        "Lente": [1.365530906741331],
        "Mod√©r√©e": [1.254301578718297],
        "Rapide": [0.45941190962711764],
        "Tr√®s Rapide": [1.0546543349524253]}
    )
    st.dataframe(df2, use_container_width=True, hide_index=True)

    # Cr√©er une "select box" permettant de choisir le mod√®le de classification
    st.subheader("3. Entra√Ænement des mod√®les")
    choix = ['Random Forest Classifier', 'Decision Tree Classifier', 'Logistic Regression']
    option = st.selectbox('_Choisissez votre mod√®le_', choix)
    st.write('Le mod√®le choisi est :', option)

    # Afficher des options √† choisir pour scruter la performance
    display = st.radio("_Choisissez l'indicateur de performance_", ('Accuracy', 'Confusion Matrix'))

    if display == 'Accuracy' and option == 'Random Forest Classifier':
        st.write('54,7%')
    elif display == 'Accuracy' and option == 'Decision Tree Classifier':
        st.write('47,6%')
    elif display == 'Accuracy' and option == 'Logistic Regression':
        st.write('40,2%')
    elif display == 'Confusion Matrix' and option == 'Random Forest Classifier':
        st.image('rf_clf_matrix.png')
    elif display == 'Confusion Matrix' and option == 'Decision Tree Classifier':
        st.image('tree_clf_matrix.png')
    elif display == 'Confusion Matrix' and option == 'Logistic Regression':
        st.image('logistic_reg_matrix.png')

if page==pages[5] :
    st.image("lfb.png")
    st.header("Conclusion üìå")

    # Section 1: Bilan
    st.subheader("1. Bilan")
    st.markdown("""
    Malgr√© les efforts fournis pour √©quilibrer les classes et ajuster les hyperparam√®tres des mod√®les, les r√©sultats obtenus restent insuffisants pour offrir des recommandations qualitatives et pr√©cises quant au temps de r√©ponse des pompiers de Londres. 
    Nous avons constat√© que les variables explicatives disponibles ne capturent pas les facteurs cl√©s influen√ßant la variable cible.
    """)

    # Section 2: Probl√®mes rencontr√©s
    st.subheader("2. Probl√®mes rencontr√©s")
    st.markdown("""
    **Jeux de donn√©es :**  
    - S√©paration initiale des jeux de donn√©es en plusieurs fichiers couvrant diverses p√©riodes, n√©cessitant de nombreuses it√©rations pour le nettoyage et le traitement des valeurs nulles.

    **Probl√®mes li√©s √† l'IT :**  
    - La volum√©trie importante du jeu de donn√©es a limit√© nos options d'encodage, n√©cessitant des regroupements dans certaines cat√©gories.

    **Pr√©visionnel :**  
    - Le temps de traitement et de nettoyage a √©t√© cons√©quent, r√©duisant la phase d'optimisation et de finalisation.
    """)

    st.subheader("3. Suite du projet")
    st.markdown("""
    Pour am√©liorer la mod√©lisation du temps de r√©ponse, nous sugg√©rons :  
    - **Ajout de nouvelles variables :** Les conditions m√©t√©orologiques et la distance entre la caserne et le lieu de l'incident pourraient affiner les pr√©dictions.
    - **Donn√©es GPS :** Int√©grer des donn√©es GPS des camions pour mesurer les distances tout en respectant l'anonymisation des lieux d'incidents.
    """)

    # Section 4: Bibliographie
    st.subheader("4. Bibliographie")

    bibliographie_choice = st.radio(
        "Quelle bibliographie souhaitez-vous consulter ?",
        ["Donn√©es", "Publications, articles et √©tudes consult√©es"]
    )

    # Contenu affich√© en fonction du choix
    if bibliographie_choice == "Donn√©es":
        st.markdown("""
        - [London Fire Brigade Incident Records - Ville de Londres](https://data.london.gov.uk/dataset/london-fire-brigade-incident-records)
        - [Mobilisation Data - Ville de Londres](https://data.london.gov.uk/dataset/london-fire-brigade-mobilisation-records)
        """)

    elif bibliographie_choice == "Publications, articles et √©tudes consult√©es":
        st.markdown("""
        - [Review and comparison of prediction algorithms for the estimated time of arrival using geospatial transportation data.](https://doi.org/10.1016/j.procs.2021.11.003)
        - [GPS is (finally) coming to the London Fire Department.](https://www.cbc.ca/news/canada/london/london-fire-department-gps-computerized-dispatch-system-field-tested-2021-1.5801119)
        - [Guide relatif aux op√©rations des services de s√©curit√© incendie.](https://cdn-contenu.quebec.ca/cdn-contenu/adm/min/securitepublique/publications-adm/publications-secteurs/securite-incendie/services-securite-incendie/guides-reference-ssi/guide_operations_2024_2_01.pdf)
        - [Modelling residential fire incident response times: A spatial analytic approach.](https://doi.org/10.1016/j.apgeog.2017.03.004)
        - [Scalable Real-time Prediction and Analysis of San Francisco Fire Department Response Times.](https://doi.org/10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00154)
        - [Survey of ETA prediction methods in public transport networks.](http://arxiv.org/abs/1904.05037)
        - [Impact of weather conditions on macroscopic urban travel times.](https://doi.org/10.1016/j.jtrangeo.2012.11.003)
        """)

